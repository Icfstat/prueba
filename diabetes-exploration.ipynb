{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:44.281754Z",
     "iopub.status.busy": "2021-10-09T02:57:44.281424Z",
     "iopub.status.idle": "2021-10-09T02:57:45.311226Z",
     "shell.execute_reply": "2021-10-09T02:57:45.310556Z",
     "shell.execute_reply.started": "2021-10-09T02:57:44.281683Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Los objetivos de este analisis son :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Conocer las variables mas importantes para predecir la readmision en pacientes diabeticos y que el modelo hipotetico sea de alta prediccion, del menor numero de variables posible para que pueda ser explicado y totalmente implementables.\n",
    "\n",
    "2. Detallar como son los experimentos con que se llego a los resultados\n",
    "\n",
    "3. Explorar algunas tecnicas de feature engineering segun sea el tipo de datos que se encontrara\n",
    "\n",
    "4. Explorar como la seleccion de variables ayuda a mejorar la prediccion y a la vez ayudar a la explicacion del modelo al hacerlo mas compacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:45.315107Z",
     "iopub.status.busy": "2021-10-09T02:57:45.314552Z",
     "iopub.status.idle": "2021-10-09T02:57:45.910745Z",
     "shell.execute_reply": "2021-10-09T02:57:45.910149Z",
     "shell.execute_reply.started": "2021-10-09T02:57:45.315071Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data=pd.read_csv('../input/diabetes-globant/diabetic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:45.912650Z",
     "iopub.status.busy": "2021-10-09T02:57:45.911929Z",
     "iopub.status.idle": "2021-10-09T02:57:45.921406Z",
     "shell.execute_reply": "2021-10-09T02:57:45.920658Z",
     "shell.execute_reply.started": "2021-10-09T02:57:45.912609Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmemos si la id 'encounter_id' es unica y si el id del paciente se repite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:45.923523Z",
     "iopub.status.busy": "2021-10-09T02:57:45.923288Z",
     "iopub.status.idle": "2021-10-09T02:57:45.939692Z",
     "shell.execute_reply": "2021-10-09T02:57:45.938868Z",
     "shell.execute_reply.started": "2021-10-09T02:57:45.923490Z"
    }
   },
   "outputs": [],
   "source": [
    "print (len(df_data['encounter_id'].unique())/len(df_data))\n",
    "\n",
    "print (len(df_data['patient_nbr'].unique())/len(df_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:45.942560Z",
     "iopub.status.busy": "2021-10-09T02:57:45.940950Z",
     "iopub.status.idle": "2021-10-09T02:57:45.958819Z",
     "shell.execute_reply": "2021-10-09T02:57:45.957778Z",
     "shell.execute_reply.started": "2021-10-09T02:57:45.942520Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data['patient_nbr'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables 'age','max_glu_serum','readmitted'(variable a predecir) y 'weight' se convierten a enteros para explotar el orden que tienen sus valores. Luego algunas etiquetas que aparecne en la data se convierten a nulo para unfirmoizar los valores perdidos en la data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:45.960645Z",
     "iopub.status.busy": "2021-10-09T02:57:45.960336Z",
     "iopub.status.idle": "2021-10-09T02:57:46.611789Z",
     "shell.execute_reply": "2021-10-09T02:57:46.611170Z",
     "shell.execute_reply.started": "2021-10-09T02:57:45.960618Z"
    }
   },
   "outputs": [],
   "source": [
    "##limpieza\n",
    "\n",
    "print(df_data['age'].value_counts())\n",
    "\n",
    "df_data['age']=df_data['age'].map({'[0-10)':1,'[10-20)':2,'[20-30)':3,'[30-40)':4,'[40-50)':5,'[50-60)':6,'[60-70)':7,'[70-80)':8})\n",
    "\n",
    "print(df_data['age'].value_counts())\n",
    "\n",
    "df_data=df_data.replace(\"?\",np.nan)\n",
    "df_data=df_data.replace(\"None\",np.nan)\n",
    "\n",
    "df_data.loc[df_data['max_glu_serum']=='Norm','max_glu_serum']=1\n",
    "df_data.loc[df_data['max_glu_serum']=='>200','max_glu_serum']=2\n",
    "df_data.loc[df_data['max_glu_serum']=='>300','max_glu_serum']=3\n",
    "\n",
    "\n",
    "df_data.loc[df_data['readmitted']=='NO','readmitted']=0\n",
    "df_data.loc[df_data['readmitted']=='<30','readmitted']=1\n",
    "df_data.loc[df_data['readmitted']=='>30','readmitted']=2\n",
    "\n",
    " \n",
    "df_data['weight']=df_data['weight'].map({'[0-25)':1,'[25-50)':2,'[50-75)':3,'[75-100)':4,'[100-125)':5,'[125-150)':6,'[150-175)':7,'[175-200)':8,'>200/':9 })\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:46.613262Z",
     "iopub.status.busy": "2021-10-09T02:57:46.612859Z",
     "iopub.status.idle": "2021-10-09T02:57:46.629589Z",
     "shell.execute_reply": "2021-10-09T02:57:46.629026Z",
     "shell.execute_reply.started": "2021-10-09T02:57:46.613231Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data['readmitted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos los valores nulos por cada variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:46.630959Z",
     "iopub.status.busy": "2021-10-09T02:57:46.630626Z",
     "iopub.status.idle": "2021-10-09T02:57:47.000816Z",
     "shell.execute_reply": "2021-10-09T02:57:47.000300Z",
     "shell.execute_reply.started": "2021-10-09T02:57:46.630916Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:47.002141Z",
     "iopub.status.busy": "2021-10-09T02:57:47.001805Z",
     "iopub.status.idle": "2021-10-09T02:57:47.020277Z",
     "shell.execute_reply": "2021-10-09T02:57:47.019672Z",
     "shell.execute_reply.started": "2021-10-09T02:57:47.002109Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def entrena_lgb(data,features,categorical,target):\n",
    "\n",
    "    kfold=KFold(n_splits=5,shuffle=True,random_state=2021)\n",
    "\n",
    "\n",
    "    i=1\n",
    "\n",
    "    r=[]\n",
    "\n",
    "    importancias=pd.DataFrame()\n",
    "\n",
    "    importancias['variable']=features\n",
    "    \n",
    "    \n",
    "    cat_ind=[features.index(x) for x in categorical if x in features]\n",
    "    \n",
    "    dict_cat={}\n",
    "    \n",
    "    categorical_numerical = data[categorical].dropna().select_dtypes(include=np.number).columns.tolist()\n",
    "    \n",
    "    categorical_transform=[x for x in categorical if x not in categorical_numerical]\n",
    "    \n",
    "    for l in categorical_transform:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(list(data[l].dropna()))\n",
    "\n",
    "        dict_cat[l]=le\n",
    "\n",
    "        data.loc[~data[l].isnull(),l]=le.transform(data.loc[~data[l].isnull(),l])\n",
    "        \n",
    "        \n",
    "\n",
    "    for train_index,test_index in kfold.split(data):\n",
    "\n",
    "        lgb_data_train = lgb.Dataset(data.loc[train_index,features].values,data.loc[train_index,target].values)\n",
    "        lgb_data_eval = lgb.Dataset(data.loc[test_index,features].values,data.loc[test_index,target].values, reference=lgb_data_train)\n",
    "\n",
    "        params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': { 'rmse'},\n",
    "            \"max_depth\":-1,\n",
    "            \"num_leaves\":32,\n",
    "            'learning_rate': 0.1,\n",
    "        \"min_child_samples\": 100,\n",
    "            'feature_fraction': 0.9,\n",
    "         \"bagging_freq\":1,\n",
    "            'bagging_fraction': 0.9,\n",
    "            \"lambda_l1\":10,\n",
    "            \"lambda_l2\":10,\n",
    "           # \"scale_pos_weight\":30,\n",
    "\n",
    "            'verbose': 1    \n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        modelo = lgb.train(params,lgb_data_train,num_boost_round=13100,valid_sets=lgb_data_eval,early_stopping_rounds=50,verbose_eval=25,categorical_feature=cat_ind)\n",
    "\n",
    "        importancias['gain_'+str(i)]=modelo.feature_importance(importance_type=\"gain\")\n",
    "\n",
    "\n",
    "        data.loc[test_index,'estimator']=modelo.predict(data.loc[test_index,features].values, num_iteration=modelo.best_iteration)\n",
    "\n",
    "        print (\"Fold_\"+str(i))\n",
    "        a= (mean_squared_error(data.loc[test_index,target],data.loc[test_index,'estimator']))**0.5\n",
    "        r.append(a)\n",
    "        print (a)\n",
    "        print (\"\")\n",
    "\n",
    "        i=i+1\n",
    "        \n",
    "    for l in categorical_transform:\n",
    "\n",
    "            data.loc[~data[l].isnull(),l]=dict_cat[l].inverse_transform(data.loc[~data[l].isnull(),l].astype(int))\n",
    "            \n",
    "    importancias[\"gain_avg\"]=importancias[[\"gain_1\",\"gain_2\",\"gain_3\",\"gain_4\",\"gain_5\"]].mean(axis=1)\n",
    "    importancias=importancias.sort_values(\"gain_avg\",ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print (\"mean: \"+str(np.mean(np.array(r))))\n",
    "    print (\"std: \"+str(np.std(np.array(r))))\n",
    "    \n",
    "    return importancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:47.021528Z",
     "iopub.status.busy": "2021-10-09T02:57:47.021243Z",
     "iopub.status.idle": "2021-10-09T02:57:47.095179Z",
     "shell.execute_reply": "2021-10-09T02:57:47.094339Z",
     "shell.execute_reply.started": "2021-10-09T02:57:47.021504Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_data['max_glu_serum'].value_counts())\n",
    "print(df_data['diag_1'].value_counts())\n",
    "print(df_data['diag_2'].value_counts())\n",
    "print(df_data['diag_3'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notar la alta cardinalidad de algunas variables categoricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:47.096541Z",
     "iopub.status.busy": "2021-10-09T02:57:47.096306Z",
     "iopub.status.idle": "2021-10-09T02:57:47.379966Z",
     "shell.execute_reply": "2021-10-09T02:57:47.379231Z",
     "shell.execute_reply.started": "2021-10-09T02:57:47.096513Z"
    }
   },
   "outputs": [],
   "source": [
    "### notar la alta cardinalidad de algunas variables categoricas\n",
    "\n",
    "for x in ['race','gender','admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "             'payer_code', 'medical_specialty','A1Cresult',\n",
    "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
    "       'glyburide-metformin', 'glipizide-metformin',\n",
    "       'glimepiride-pioglitazone', 'metformin-rosiglitazone','metformin-pioglitazone','change', 'diabetesMed','diag_1','diag_2','diag_3']:\n",
    "    \n",
    "    print(x)\n",
    "    print(df_data[x].nunique())\n",
    "    print('')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Primer Experimento - Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creare a conintuacion el modelo baseline que sus variables seran tal y como vienen en la data luego de la limpiaza inicial que se realizo.\n",
    "\n",
    "Para predecir la readmision se opta por una regresion para aprovechar el orden que hay entre los valores, el cual no ocurriria si se optaria por una clasificacion multinomial.\n",
    "\n",
    "Se realizara una validacion cruzada al no observar un patron de dependencia del tiempo entre las observaciones, luego el modelo se optimizara con rmse y finalmente con un optimizador se convertira los valores decimales que arroja la prediccion a 0 , 1 y 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:57:47.381163Z",
     "iopub.status.busy": "2021-10-09T02:57:47.380921Z",
     "iopub.status.idle": "2021-10-09T02:58:28.326279Z",
     "shell.execute_reply": "2021-10-09T02:58:28.325415Z",
     "shell.execute_reply.started": "2021-10-09T02:57:47.381138Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "categorical=['patient_nbr','race','gender','admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "             'payer_code', 'medical_specialty','A1Cresult',\n",
    "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
    "       'glyburide-metformin', 'glipizide-metformin',\n",
    "       'glimepiride-pioglitazone', 'metformin-rosiglitazone','metformin-pioglitazone','change', 'diabetesMed','diag_1','diag_2','diag_3']\n",
    "\n",
    "no_usar=['encounter_id','readmitted','estimator']\n",
    "\n",
    "features=[x for x in df_data.columns if x not in no_usar]\n",
    "\n",
    "importancias=entrena_lgb(data=df_data,features=features,categorical=categorical,target='readmitted')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:58:28.331087Z",
     "iopub.status.busy": "2021-10-09T02:58:28.330311Z",
     "iopub.status.idle": "2021-10-09T02:58:28.355983Z",
     "shell.execute_reply": "2021-10-09T02:58:28.355415Z",
     "shell.execute_reply.started": "2021-10-09T02:58:28.331041Z"
    }
   },
   "outputs": [],
   "source": [
    "importancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usa el siguiente optimizador para elegir los puntos de corte que convertiran los valores predicho en 0 , 1 2 en el caso que este modelo tenga que ser pasado a un ambiente productivo. Esto es mucho mas ventajoso que redondear las predicciones solamente al entero mas cercano.\n",
    "\n",
    "El codigo de dicho optimizador esta basado en el codigo del siguiente enlace:\n",
    "\n",
    "https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:58:28.357859Z",
     "iopub.status.busy": "2021-10-09T02:58:28.357049Z",
     "iopub.status.idle": "2021-10-09T02:58:28.368134Z",
     "shell.execute_reply": "2021-10-09T02:58:28.367224Z",
     "shell.execute_reply.started": "2021-10-09T02:58:28.357814Z"
    }
   },
   "outputs": [],
   "source": [
    "## basado en esto https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "class OptRounder(object):\n",
    "    def __init__(self):\n",
    "        self.res_ = []\n",
    "        self.coef_ = []\n",
    "        \n",
    "    def get_res(self):\n",
    "        return self.res_\n",
    "    \n",
    "    # objective function\n",
    "    def func(self, coef, X, y):\n",
    "\n",
    "        mse = mean_squared_error(self.bincut(coef, X), y)\n",
    "        return mse\n",
    "    \n",
    "    \n",
    "    def bincut(self, coef, X):\n",
    "        return pd.cut(X,\n",
    "                      [-np.inf] + list(np.sort(coef)) + [np.inf],\n",
    "                      labels = [0, 1, 2])\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pfunc = partial(self.func, X=X, y=y)\n",
    "        self.res_ = sp.optimize.minimize(fun = pfunc,           # objective func\n",
    "                                         x0 = [0.5, 1.2],  # initial coef\n",
    "                                         method='nelder-mead')  # solver\n",
    "        \n",
    "        \n",
    "        self.coef_ = self.res_.x\n",
    "        \n",
    "    def predict(self, X, coef):\n",
    "        return self.bincut(coef, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:58:28.369867Z",
     "iopub.status.busy": "2021-10-09T02:58:28.369265Z",
     "iopub.status.idle": "2021-10-09T02:58:28.657742Z",
     "shell.execute_reply": "2021-10-09T02:58:28.657092Z",
     "shell.execute_reply.started": "2021-10-09T02:58:28.369825Z"
    }
   },
   "outputs": [],
   "source": [
    "optR = OptRounder()\n",
    "optR.fit(df_data[\"estimator\"].values.reshape(-1,), df_data['readmitted'].astype(int))\n",
    "res = optR.get_res() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:58:28.659130Z",
     "iopub.status.busy": "2021-10-09T02:58:28.658878Z",
     "iopub.status.idle": "2021-10-09T02:58:28.676409Z",
     "shell.execute_reply": "2021-10-09T02:58:28.675652Z",
     "shell.execute_reply.started": "2021-10-09T02:58:28.659102Z"
    }
   },
   "outputs": [],
   "source": [
    "coefficients = res.x        \n",
    "\n",
    "\n",
    "(mean_squared_error(optR.predict(df_data[\"estimator\"].values, coefficients).astype(int),df_data['readmitted'].astype(int)))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que 0.913 es el valor de nuestra baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:58:28.677617Z",
     "iopub.status.busy": "2021-10-09T02:58:28.677409Z",
     "iopub.status.idle": "2021-10-09T02:58:28.684013Z",
     "shell.execute_reply": "2021-10-09T02:58:28.683247Z",
     "shell.execute_reply.started": "2021-10-09T02:58:28.677593Z"
    }
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Segundo Experimento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que en la importancia de variables del primer experimento que 'diag_1','diag_2' y 'diag_3' son las variables mas importantes y tienen alta cardinalidad. En estos casos muchas veces estas variables tienden a overfitear por mas que salgan como las variables mas relevantes. Probemos extrayendo estas variables en nuestro segundo experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T02:58:28.686195Z",
     "iopub.status.busy": "2021-10-09T02:58:28.685539Z",
     "iopub.status.idle": "2021-10-09T03:00:37.565680Z",
     "shell.execute_reply": "2021-10-09T03:00:37.563994Z",
     "shell.execute_reply.started": "2021-10-09T02:58:28.686156Z"
    }
   },
   "outputs": [],
   "source": [
    "no_usar=['encounter_id','readmitted','estimator', 'diag_1','diag_2','diag_3']\n",
    "\n",
    "features=[x for x in df_data.columns if x not in no_usar]\n",
    "\n",
    "importancias_2=entrena_lgb(data=df_data,features=features,categorical=categorical,target='readmitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tan solo sacando esas 3 variables el score bajo de 0.870 a 0.866 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tercer Experimento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos sacando el promedio y varianza del 'number_patient'(variable numerica mas relevante) en variables de alta cardinalidad , volveremos a poner las 3 variables extraidas anteriormente y veremos mas abajo que el score sera practicamente el mismo de la baseline. El codigo que esta comentado tambien fueron variables que se crearon con la logica hablada pero los resultados seguian siendo basicamente los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:00:37.567854Z",
     "iopub.status.busy": "2021-10-09T03:00:37.567353Z",
     "iopub.status.idle": "2021-10-09T03:00:37.623489Z",
     "shell.execute_reply": "2021-10-09T03:00:37.622680Z",
     "shell.execute_reply.started": "2021-10-09T03:00:37.567809Z"
    }
   },
   "outputs": [],
   "source": [
    "### probamos haciendo algo de feature engineering a las variables mas importantes, en caso alguna salga como relevante, se puede discutir la razon de su relevancia\n",
    "\n",
    "#for x in [ 'diag_1',\n",
    "# 'diag_2',\n",
    "# 'diag_3']:\n",
    "    \n",
    "#    df_data[x+\"_size\"]=df_data.groupby(x)['encounter_id'].transform('size')\n",
    "    \n",
    "#for x in [ 'diag_1',\n",
    "# 'diag_2',\n",
    "# 'diag_3']:\n",
    "    \n",
    "#    df_data[x+\"_number_inpatient_mean\"]=df_data.groupby(x)['number_inpatient'].transform('mean')\n",
    "#    df_data[x+\"_number_inpatient_var\"]=df_data.groupby(x)['number_inpatient'].transform('var')\n",
    "\n",
    "for x in [ 'discharge_disposition_id',\n",
    " 'admission_source_id',\n",
    " 'medical_specialty']:\n",
    "    \n",
    "    df_data[x+\"_number_inpatient_mean\"]=df_data.groupby(x)['number_inpatient'].transform('mean')\n",
    "    df_data[x+\"_number_inpatient_var\"]=df_data.groupby(x)['number_inpatient'].transform('var')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:00:37.625346Z",
     "iopub.status.busy": "2021-10-09T03:00:37.624875Z",
     "iopub.status.idle": "2021-10-09T03:01:21.234073Z",
     "shell.execute_reply": "2021-10-09T03:01:21.233179Z",
     "shell.execute_reply.started": "2021-10-09T03:00:37.625315Z"
    }
   },
   "outputs": [],
   "source": [
    "no_usar=['encounter_id','readmitted','estimator']\n",
    "\n",
    "features=[x for x in df_data.columns if x not in no_usar]\n",
    "\n",
    "importancias_2=entrena_lgb(data=df_data,features=features,categorical=categorical,target='readmitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vemos que el score el mismo o incluso ligeramente peor que en la baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:01:21.235611Z",
     "iopub.status.busy": "2021-10-09T03:01:21.235369Z",
     "iopub.status.idle": "2021-10-09T03:01:21.262499Z",
     "shell.execute_reply": "2021-10-09T03:01:21.261855Z",
     "shell.execute_reply.started": "2021-10-09T03:01:21.235582Z"
    }
   },
   "outputs": [],
   "source": [
    "importancias_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cuarto Experimento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el **target encoding** para las 6 variables con mas alta cardinalidad pero usando las mismas particiones de la validacion cruzada usada para evitar el **data leakage.**\n",
    "\n",
    "Recordemos que a diferencia del segundo experimento, no se ha sacado ninguna variable categorica.\n",
    "\n",
    "La funcion de target encoding creada,hace que cuando el tama;o de muestra es menor a 20, se asigna como valor nulo a la variable creada para evitar efectos de tamaño de muestra pequeño. Dicho tamaño de muestra es una parametro de la funcion que se puede variar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:01:21.264040Z",
     "iopub.status.busy": "2021-10-09T03:01:21.263823Z",
     "iopub.status.idle": "2021-10-09T03:01:21.273105Z",
     "shell.execute_reply": "2021-10-09T03:01:21.272257Z",
     "shell.execute_reply.started": "2021-10-09T03:01:21.264015Z"
    }
   },
   "outputs": [],
   "source": [
    "def target_encoding(data,variable,target,threshold=20,function='mean'):\n",
    "\n",
    "    list_part=[]\n",
    "\n",
    "\n",
    "    kfold=KFold(n_splits=5,shuffle=True,random_state=2021)\n",
    "\n",
    "    for train_index,test_index in kfold.split(data):\n",
    "\n",
    "        temp=data.loc[train_index].groupby(variable)[target].agg([function,'size']).reset_index()\n",
    "\n",
    "        temp=temp.loc[temp['size']>threshold].reset_index(drop=True)\n",
    "\n",
    "        del temp['size'] ; gc.collect()\n",
    "\n",
    "        temp=temp.rename(columns={function:function+'_enconding_'+variable+\"-\"+target})\n",
    "        \n",
    "        part=data.loc[test_index,['encounter_id',variable]]\n",
    "\n",
    "        part=part.merge(temp,on=variable,how='left')\n",
    "\n",
    "        list_part.append(part)\n",
    "\n",
    "    df_part=pd.concat(list_part,ignore_index=True)\n",
    "    \n",
    "    del df_part[variable] ; gc.collect()\n",
    "    \n",
    "    data=data.merge(df_part,on='encounter_id',how='left')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:01:21.274990Z",
     "iopub.status.busy": "2021-10-09T03:01:21.274351Z",
     "iopub.status.idle": "2021-10-09T03:01:45.546186Z",
     "shell.execute_reply": "2021-10-09T03:01:45.545459Z",
     "shell.execute_reply.started": "2021-10-09T03:01:21.274951Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data=target_encoding(data=df_data,variable='diag_1',target='readmitted')\n",
    "df_data=target_encoding(data=df_data,variable='diag_2',target='readmitted')\n",
    "df_data=target_encoding(data=df_data,variable='diag_3',target='readmitted')\n",
    "df_data=target_encoding(data=df_data,variable='discharge_disposition_id',target='readmitted')\n",
    "df_data=target_encoding(data=df_data,variable='admission_source_id',target='readmitted')\n",
    "df_data=target_encoding(data=df_data,variable='medical_specialty',target='readmitted')\n",
    "\n",
    "df_data=target_encoding(data=df_data,variable='diag_1',target='readmitted',function='var')\n",
    "df_data=target_encoding(data=df_data,variable='diag_2',target='readmitted',function='var')\n",
    "df_data=target_encoding(data=df_data,variable='diag_3',target='readmitted',function='var')\n",
    "df_data=target_encoding(data=df_data,variable='discharge_disposition_id',target='readmitted',function='var')\n",
    "df_data=target_encoding(data=df_data,variable='admission_source_id',target='readmitted',function='var')\n",
    "df_data=target_encoding(data=df_data,variable='medical_specialty',target='readmitted',function='var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:01:45.548156Z",
     "iopub.status.busy": "2021-10-09T03:01:45.547574Z",
     "iopub.status.idle": "2021-10-09T03:02:30.289650Z",
     "shell.execute_reply": "2021-10-09T03:02:30.287892Z",
     "shell.execute_reply.started": "2021-10-09T03:01:45.548113Z"
    }
   },
   "outputs": [],
   "source": [
    "no_usar=['encounter_id','readmitted','estimator']\n",
    "\n",
    "features=[x for x in df_data.columns if x not in no_usar]\n",
    "\n",
    "importancias_3=entrena_lgb(data=df_data,features=features,categorical=categorical,target='readmitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de las variables agregadas, el score continua siendo practicamente el mismo de la baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:02:30.291705Z",
     "iopub.status.busy": "2021-10-09T03:02:30.291376Z",
     "iopub.status.idle": "2021-10-09T03:02:30.308857Z",
     "shell.execute_reply": "2021-10-09T03:02:30.308188Z",
     "shell.execute_reply.started": "2021-10-09T03:02:30.291665Z"
    }
   },
   "outputs": [],
   "source": [
    "importancias_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Quinto Experimento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien vimos que las 3 variables categoricas que sacamos en el segundo experimento estaban overfiteando y tambien puede ser confirmado al regresarlas en los 2 experimentos anteriores. Tal vez algunos de los niveles de dichas variables si podrian tener poder predictivo y podrian estar representados en el target encoding.\n",
    "\n",
    "Entonces mantengamos las variables creadas  el target encoding pero volvamos a extraer las 3 variables con mas alta cardinalidad como en el segundo experimento y veamos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:02:30.310615Z",
     "iopub.status.busy": "2021-10-09T03:02:30.310234Z",
     "iopub.status.idle": "2021-10-09T03:04:31.852942Z",
     "shell.execute_reply": "2021-10-09T03:04:31.852031Z",
     "shell.execute_reply.started": "2021-10-09T03:02:30.310586Z"
    }
   },
   "outputs": [],
   "source": [
    "no_usar=['encounter_id','readmitted','estimator','diag_1','diag_2','diag_3']\n",
    "\n",
    "features=[x for x in df_data.columns if x not in no_usar]\n",
    "\n",
    "importancias_4=entrena_lgb(data=df_data,features=features,categorical=categorical,target='readmitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la hipotesis se hace cierta y superamos al score del segundo experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:04:31.854920Z",
     "iopub.status.busy": "2021-10-09T03:04:31.854677Z",
     "iopub.status.idle": "2021-10-09T03:04:31.870855Z",
     "shell.execute_reply": "2021-10-09T03:04:31.870292Z",
     "shell.execute_reply.started": "2021-10-09T03:04:31.854890Z"
    }
   },
   "outputs": [],
   "source": [
    "importancias_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces probemos el score optimizando los puntos de corte como se hablo anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:04:31.872324Z",
     "iopub.status.busy": "2021-10-09T03:04:31.871765Z",
     "iopub.status.idle": "2021-10-09T03:04:32.121983Z",
     "shell.execute_reply": "2021-10-09T03:04:32.121173Z",
     "shell.execute_reply.started": "2021-10-09T03:04:31.872277Z"
    }
   },
   "outputs": [],
   "source": [
    "optR = OptRounder()\n",
    "optR.fit(df_data[\"estimator\"].values.reshape(-1,), df_data['readmitted'].astype(int))\n",
    "res = optR.get_res() \n",
    "\n",
    "\n",
    "coefficients = res.x        \n",
    "\n",
    "(mean_squared_error(optR.predict(df_data[\"estimator\"].values, coefficients).astype(int),df_data['readmitted'].astype(int)))**0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se confirma que se vuelve a superar el score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sexto Experimento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraigamos las variables con 'gain_avg' mayor a 0 y esperemos encontrar un score mejor o similar. Lo comprobaremos en los resultados de mas abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:04:32.123136Z",
     "iopub.status.busy": "2021-10-09T03:04:32.122912Z",
     "iopub.status.idle": "2021-10-09T03:06:33.910313Z",
     "shell.execute_reply": "2021-10-09T03:06:33.909402Z",
     "shell.execute_reply.started": "2021-10-09T03:04:32.123107Z"
    }
   },
   "outputs": [],
   "source": [
    "features_selected=importancias_4.loc[importancias_4['gain_avg']>0,'variable'].tolist()\n",
    "\n",
    "print(len(features_selected))\n",
    "\n",
    "importancias_5=entrena_lgb(data=df_data,features=features_selected,categorical=categorical,target='readmitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que pasando de las 65 variables originales a 50 variables, obtenemos un modelo de resultados muy similares al del mejor escore que es el del experimento anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Septimo Experimento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionemos variables usando el metodo de target perumutation que basicamente hace que para cada una de las variables es permutar el target muchas veces y compara si el score sin el target permutado tiene diferencia significativa con los score con target permutado. En caso eso sea cierto, la variable queda seleccionada.\n",
    "\n",
    "La metodologia y implementacion se base en los siguientes enlaces:\n",
    "\n",
    "https://www.kaggle.com/ogrellier/feature-selection-with-null-importances\n",
    "\n",
    "https://academic.oup.com/bioinformatics/article/26/10/1340/193348\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:06:33.913184Z",
     "iopub.status.busy": "2021-10-09T03:06:33.912916Z",
     "iopub.status.idle": "2021-10-09T03:06:33.931042Z",
     "shell.execute_reply": "2021-10-09T03:06:33.930366Z",
     "shell.execute_reply.started": "2021-10-09T03:06:33.913153Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_importance( data,features,categorical,target,shuffle=True, seed=None):\n",
    "\n",
    "    \n",
    "    cat_ind=[features.index(x) for x in categorical if x in features]\n",
    "    \n",
    "    dict_cat={}\n",
    "    \n",
    "    categorical_numerical = data[categorical].dropna().select_dtypes(include=np.number).columns.tolist()\n",
    "    \n",
    "    categorical_transform=[x for x in categorical if x not in categorical_numerical]\n",
    "    \n",
    "    for l in categorical_transform:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(list(data[l].dropna()))\n",
    "\n",
    "        dict_cat[l]=le\n",
    "\n",
    "        data.loc[~data[l].isnull(),l]=le.transform(data.loc[~data[l].isnull(),l])\n",
    "    \n",
    "    y = data[target].copy()\n",
    "    if shuffle:\n",
    "        y = data[target].copy().sample(frac=1.0,random_state=seed)\n",
    "    \n",
    "    dtrain = lgb.Dataset(data[features].values, y.values, free_raw_data=False, silent=True)\n",
    "    lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': 'gbdt',\n",
    "     \"learning_rate\": 0.2,\n",
    "        'metric': { 'rmse'},\n",
    "        'subsample': 0.9,\n",
    "        'colsample_bytree': 0.9,\n",
    "            \"min_child_samples\": 100,\n",
    "        'num_leaves': 64,\n",
    "        'max_depth': -1,\n",
    "        'seed': seed,\n",
    "        'bagging_freq': 1,\n",
    "    }\n",
    "    \n",
    "    # Fit the model\n",
    "    clf = lgb.train(params=lgb_params, train_set=dtrain, num_boost_round=90,categorical_feature=cat_ind)\n",
    "\n",
    "    # Get feature importances\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df[\"feature\"] = list(features)\n",
    "    imp_df[\"importance_gain\"] = clf.feature_importance(importance_type='gain')\n",
    "    imp_df['trn_score'] = mean_squared_error(y, clf.predict(data[features].values))\n",
    "    \n",
    "    for l in categorical_transform:\n",
    "\n",
    "            data.loc[~data[l].isnull(),l]=dict_cat[l].inverse_transform(data.loc[~data[l].isnull(),l].astype(int))\n",
    "    \n",
    "    return imp_df\n",
    "\n",
    "\n",
    "def get_importance_permutation(data,variables,categorical,target,n_iterations=50):\n",
    "\n",
    "    for x in range(1,n_iterations):\n",
    "        temp=get_feature_importance(data=data,features=variables,categorical=categorical,target=target,shuffle=True, seed=x)\n",
    "        temp[\"run\"]=x\n",
    "\n",
    "        if x==1:\n",
    "            general=temp.copy()\n",
    "\n",
    "        else :\n",
    "            general=general.append(temp,ignore_index=True)\n",
    "\n",
    "        print(x)\n",
    "\n",
    "\n",
    "    ranking=get_feature_importance(data=data,features=variables,categorical=categorical,target=target,shuffle=False, seed=2021)\n",
    "\n",
    "    features_quantile=general.groupby(\"feature\")[\"importance_gain\"].quantile(0.95).reset_index()\n",
    "\n",
    "    features_quantile=features_quantile.rename(columns={\"importance_gain\":\"quantile_0.95\"})\n",
    "    ranking=ranking.merge(features_quantile,on=\"feature\",how=\"left\")\n",
    "\n",
    "    ranking=ranking.sort_values(\"importance_gain\",ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T03:06:33.932816Z",
     "iopub.status.busy": "2021-10-09T03:06:33.931901Z",
     "iopub.status.idle": "2021-10-09T04:00:13.961775Z",
     "shell.execute_reply": "2021-10-09T04:00:13.961018Z",
     "shell.execute_reply.started": "2021-10-09T03:06:33.932773Z"
    }
   },
   "outputs": [],
   "source": [
    "importances_6=get_importance_permutation(data=df_data,variables=features_selected,categorical=categorical,target='readmitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T04:02:02.299776Z",
     "iopub.status.busy": "2021-10-09T04:02:02.299192Z",
     "iopub.status.idle": "2021-10-09T04:02:02.318807Z",
     "shell.execute_reply": "2021-10-09T04:02:02.317946Z",
     "shell.execute_reply.started": "2021-10-09T04:02:02.299741Z"
    }
   },
   "outputs": [],
   "source": [
    "importances_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T04:06:48.802602Z",
     "iopub.status.busy": "2021-10-09T04:06:48.801539Z",
     "iopub.status.idle": "2021-10-09T04:08:52.914896Z",
     "shell.execute_reply": "2021-10-09T04:08:52.914104Z",
     "shell.execute_reply.started": "2021-10-09T04:06:48.802544Z"
    }
   },
   "outputs": [],
   "source": [
    "features_selected_2=importances_6.loc[importances_6['importance_gain']>importances_6['quantile_0.95'],'feature'].tolist()\n",
    "\n",
    "print(len(features_selected_2))\n",
    "\n",
    "importancias_7=entrena_lgb(data=df_data,features=features_selected_2,categorical=categorical,target='readmitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el target encoding incluso llega a descartar variables que estan adelante en el ranking de importancias, como 'var_enconding_diag_1-readmitted'.Finalmente con el target permutation obtenemos un modelo de solo 30 variables con un score que supera a la baseline y de casi el mismo score que el mejor modelo en los experimentos realizados.\n",
    "\n",
    "Las variables seleccionadas en orden de relevancia para el modelo bajo los test respectivos son las siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T04:12:35.093525Z",
     "iopub.status.busy": "2021-10-09T04:12:35.092899Z",
     "iopub.status.idle": "2021-10-09T04:12:35.100966Z",
     "shell.execute_reply": "2021-10-09T04:12:35.100104Z",
     "shell.execute_reply.started": "2021-10-09T04:12:35.093471Z"
    }
   },
   "outputs": [],
   "source": [
    "importancias_7['variable'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variales que se descartaron fueron:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T04:15:09.308004Z",
     "iopub.status.busy": "2021-10-09T04:15:09.307254Z",
     "iopub.status.idle": "2021-10-09T04:15:09.316448Z",
     "shell.execute_reply": "2021-10-09T04:15:09.315640Z",
     "shell.execute_reply.started": "2021-10-09T04:15:09.307962Z"
    }
   },
   "outputs": [],
   "source": [
    "no_usar=['encounter_id','readmitted','estimator']\n",
    "\n",
    "variables=[x for x in df_data.columns if x not in no_usar]\n",
    "\n",
    "variables_descartadas=[x for x in variables if x not in features_selected_2]\n",
    "\n",
    "variables_descartadas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
